{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4f87fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>graft_type</th>\n",
       "      <th>vent_hist</th>\n",
       "      <th>...</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>efs</th>\n",
       "      <th>efs_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TBI +- Other, &gt;cGy</td>\n",
       "      <td>No</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>MEL</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                       dri_score psych_disturb    cyto_score diabetes  \\\n",
       "0   0  N/A - non-malignant indication            No           NaN       No   \n",
       "1   1                    Intermediate            No  Intermediate       No   \n",
       "2   2  N/A - non-malignant indication            No           NaN       No   \n",
       "3   3                            High            No  Intermediate       No   \n",
       "4   4                            High            No           NaN       No   \n",
       "\n",
       "   hla_match_c_high          tbi_status arrhythmia        graft_type  \\\n",
       "0               NaN              No TBI         No       Bone marrow   \n",
       "1               2.0  TBI +- Other, >cGy         No  Peripheral blood   \n",
       "2               2.0              No TBI         No       Bone marrow   \n",
       "3               2.0              No TBI         No       Bone marrow   \n",
       "4               2.0              No TBI         No  Peripheral blood   \n",
       "\n",
       "  vent_hist  ... karnofsky_score hepatic_mild          tce_div_match  \\\n",
       "0        No  ...            90.0           No                    NaN   \n",
       "1        No  ...            90.0           No  Permissive mismatched   \n",
       "2        No  ...            90.0           No  Permissive mismatched   \n",
       "3        No  ...            90.0          Yes  Permissive mismatched   \n",
       "4        No  ...            90.0           No  Permissive mismatched   \n",
       "\n",
       "  donor_related      melphalan_dose cardiac  hla_match_drb1_high  \\\n",
       "0     Unrelated  N/A, Mel not given      No                  2.0   \n",
       "1       Related  N/A, Mel not given      No                  2.0   \n",
       "2       Related  N/A, Mel not given      No                  2.0   \n",
       "3     Unrelated  N/A, Mel not given      No                  2.0   \n",
       "4       Related                 MEL      No                  2.0   \n",
       "\n",
       "   pulm_moderate  efs efs_time  \n",
       "0             No  0.0   42.356  \n",
       "1            Yes  1.0    4.672  \n",
       "2             No  0.0   19.793  \n",
       "3             No  0.0  102.349  \n",
       "4             No  0.0   16.223  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lifelines import NelsonAalenFitter  # 引入NelsonAalenFitter\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# 删除唯一标识符和缺失值过多的列\n",
    "columns_to_drop = [\n",
    "    'cyto_score_detail', \n",
    "    'renal_issue',\n",
    "    'hla_high_res_10',\n",
    "    'hla_low_res_6',\n",
    "    'rheum_issue',\n",
    "    'hla_low_res_8',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_c_low',  # Importance: 0.06591817809956657\n",
    "    'rituximab',        # Importance: 0.05381579652762678\n",
    "    'hla_low_res_10',   # Importance: 0.030017220216923903\n",
    "    'hla_high_res_8',   # Importance: 0.02714947179965365\n",
    "]\n",
    "columns_to_drop1 = [\n",
    "    'cyto_score_detail', \n",
    "    'renal_issue',\n",
    "    'hla_high_res_10',\n",
    "    'hla_low_res_6',\n",
    "    'rheum_issue',\n",
    "    'hla_low_res_8',\n",
    "    'hla_match_drb1_low',\n",
    "    'hla_match_c_low',  # Importance: 0.06591817809956657\n",
    "    'rituximab',        # Importance: 0.05381579652762678\n",
    "    'hla_low_res_10',   # Importance: 0.030017220216923903\n",
    "    'hla_high_res_8',   # Importance: 0.02714947179965365\n",
    "]\n",
    "\n",
    "# 保留原始的 ID 列，最后输出用\n",
    "id_column = test_data['ID']\n",
    "\n",
    "df.drop(columns=columns_to_drop1, inplace=True)\n",
    "test_data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4543d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 28800.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 24180.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 23516.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 23601.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 24603.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 24606.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 24499.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 26992.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 26235.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 26410.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 24712.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 28323.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 27930.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: For N > 5000, computed p-value may not be accurate. Current N is 25448.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n",
      "C:\\Users\\15951\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:531: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "import pandas as pd\n",
    "\n",
    "# 假设df和test_data已经是预处理过的数据框\n",
    "\n",
    "# 正态分布填补数值型数据缺失值\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in ['int64', 'float64']:  # 只对数值型数据处理\n",
    "        # 检查是否是正态分布（假设df[col]有非缺失值）\n",
    "        try:\n",
    "            stat, p = shapiro(df[col].dropna())  # 进行正态性检验\n",
    "        except ValueError:  # 如果该列全是缺失值，跳过该列\n",
    "            continue\n",
    "        \n",
    "        if p > 0.05:  # 认为数据服从正态分布\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            \n",
    "            # 找到缺失的位置\n",
    "            missing = df[col].isnull()\n",
    "            \n",
    "            # 生成填补的数值数量等于缺失的数量\n",
    "            fill_values = np.random.normal(mean, std, size=missing.sum())\n",
    "            \n",
    "            # 替换缺失值\n",
    "            df.loc[missing, col] = fill_values\n",
    "\n",
    "\n",
    "# 对于 object 类型的列使用基于频率的正态分布填充缺失值\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    # 计算类别的频率（出现的概率）\n",
    "    freq = df[col].value_counts(normalize=True)\n",
    "    \n",
    "    # 获取缺失值的位置\n",
    "    missing = df[col].isnull()\n",
    "    \n",
    "    # 从已知的类别中，根据频率随机选择填充值\n",
    "    fill_values = np.random.choice(freq.index, size=missing.sum(), p=freq.values)\n",
    "    \n",
    "    # 填充缺失值\n",
    "    df.loc[missing, col] = fill_values\n",
    "\n",
    "# 对 test_data 也进行相同处理\n",
    "for col in test_data.select_dtypes(include=['object']).columns:\n",
    "    freq = test_data[col].value_counts(normalize=True)\n",
    "    missing = test_data[col].isnull()\n",
    "    fill_values = np.random.choice(freq.index, size=missing.sum(), p=freq.values)\n",
    "    test_data.loc[missing, col] = fill_values\n",
    "\n",
    "\n",
    "for col in test_data.columns:\n",
    "    if test_data[col].dtype in ['int64', 'float64']:  # 只对数值型数据处理\n",
    "        try:\n",
    "            stat, p = shapiro(test_data[col].dropna())  # 进行正态性检验\n",
    "        except ValueError:  # 如果该列全是缺失值，跳过该列\n",
    "            continue\n",
    "        \n",
    "        if p > 0.05:  # 认为数据服从正态分布\n",
    "            mean = test_data[col].mean()\n",
    "            std = test_data[col].std()\n",
    "            \n",
    "            # 找到缺失的位置\n",
    "            missing = test_data[col].isnull()\n",
    "            \n",
    "            # 生成填补的数值数量等于缺失的数量\n",
    "            fill_values = np.random.normal(mean, std, size=missing.sum())\n",
    "            \n",
    "            # 替换缺失值\n",
    "            test_data.loc[missing, col] = fill_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac4514",
   "metadata": {},
   "source": [
    "## 认为数据属于正态分布的做法并没有让数据变好很多，以至于在部分情况下可能让数据预处理变差（这点我深感疑惑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951b0910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6903885\ttotal: 195ms\tremaining: 3m 14s\n",
      "500:\tlearn: 0.5884456\ttotal: 14.1s\tremaining: 14s\n",
      "999:\tlearn: 0.5792066\ttotal: 29s\tremaining: 0us\n",
      "Fold 1:\n",
      "  C-index: 0.6211\n",
      "  Accuracy: 0.6698\n",
      "----------------------------------------\n",
      "0:\tlearn: 0.6907329\ttotal: 32.3ms\tremaining: 32.3s\n",
      "500:\tlearn: 0.5940500\ttotal: 16s\tremaining: 15.9s\n",
      "999:\tlearn: 0.5840393\ttotal: 32.6s\tremaining: 0us\n",
      "Fold 2:\n",
      "  C-index: 0.6428\n",
      "  Accuracy: 0.6816\n",
      "----------------------------------------\n",
      "0:\tlearn: 0.6907765\ttotal: 39.3ms\tremaining: 39.3s\n",
      "500:\tlearn: 0.5945591\ttotal: 16.4s\tremaining: 16.3s\n",
      "999:\tlearn: 0.5856975\ttotal: 32.8s\tremaining: 0us\n",
      "Fold 3:\n",
      "  C-index: 0.6417\n",
      "  Accuracy: 0.6875\n",
      "----------------------------------------\n",
      "0:\tlearn: 0.6906322\ttotal: 39.8ms\tremaining: 39.8s\n",
      "500:\tlearn: 0.5922731\ttotal: 17.1s\tremaining: 17s\n",
      "999:\tlearn: 0.5829832\ttotal: 35.6s\tremaining: 0us\n",
      "Fold 4:\n",
      "  C-index: 0.6305\n",
      "  Accuracy: 0.6849\n",
      "----------------------------------------\n",
      "0:\tlearn: 0.6906037\ttotal: 57.6ms\tremaining: 57.5s\n",
      "500:\tlearn: 0.5922533\ttotal: 19.2s\tremaining: 19.1s\n",
      "999:\tlearn: 0.5825412\ttotal: 39.3s\tremaining: 0us\n",
      "Fold 5:\n",
      "  C-index: 0.6380\n",
      "  Accuracy: 0.6780\n",
      "----------------------------------------\n",
      "\n",
      "汇总结果:\n",
      "平均 C-index: 0.6348 (±0.0081)\n",
      "调整后 C-index: 0.6267\n",
      "\n",
      "平均准确率: 0.6803 (±0.0062)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "\n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    \n",
    "    for col in submission.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f'Submission column {col} must be numeric')\n",
    "    \n",
    "    # 合并数据并分组计算\n",
    "    merged_df = pd.concat([solution, submission], axis=1)\n",
    "    merged_df_race_groups = merged_df.groupby('race_group')\n",
    "    \n",
    "    metric_list = []\n",
    "    for _, group_df in merged_df_race_groups:\n",
    "        c_index = concordance_index(\n",
    "            group_df['efs_time'],\n",
    "            -group_df['prediction'],  # 假设预测值越大代表风险越高\n",
    "            group_df['efs']\n",
    "        )\n",
    "        metric_list.append(c_index)\n",
    "    \n",
    "    return float(np.mean(metric_list) - np.sqrt(np.var(metric_list)))\n",
    "\n",
    "solution_df = df[['ID', 'efs', 'efs_time', 'race_group']].copy()\n",
    "X = df.drop(['efs', 'efs_time', 'ID', 'race_group'], axis=1)  # 移除目标列和分组列\n",
    "y = df['efs']  # 事件发生标签\n",
    "\n",
    "# 单调性约束\n",
    "monotone_constraints = {\n",
    "    'hla_high_res_6': -1,\n",
    "    'hla_match_a_high': -1,\n",
    "    'hla_match_dqb1_low': -1,\n",
    "    'hla_nmdp_6': -1,\n",
    "}\n",
    "monotonic_dict = {col: monotone_constraints.get(col, 0) for col in X.columns}\n",
    "\n",
    "# 交叉验证\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "\n",
    "# 存储指标的列表\n",
    "c_index_metrics = []\n",
    "accuracies = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    solution_test = solution_df.iloc[test_idx].copy().reset_index(drop=True)\n",
    "    \n",
    "    # CatBoost 模型，其中部分参数似乎只适用于r语言，此处是可用于python\n",
    "    model = CatBoostClassifier(\n",
    "        learning_rate=0.03,\n",
    "        depth=3,\n",
    "        iterations=1000,\n",
    "        l2_leaf_reg=0.5,\n",
    "        verbose=500,\n",
    "        task_type='CPU',\n",
    "        cat_features=list(X_train.select_dtypes(include='object').columns),\n",
    "        monotone_constraints=monotonic_dict\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    pred_proba = model.predict_proba(X_test)[:, 1]  # 用于C-index\n",
    "    y_pred = model.predict(X_test)                 # 用于准确率\n",
    "    \n",
    "    # 计算C-index，我不确定是否完全符合题目公式\n",
    "    submission_test = pd.DataFrame({\n",
    "        'ID': solution_test['ID'],\n",
    "        'prediction': pred_proba\n",
    "    })\n",
    "    fold_c_index = score(solution_test, submission_test, 'ID')\n",
    "    c_index_metrics.append(fold_c_index)\n",
    "\n",
    "    # 计算准确率\n",
    "    fold_accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(fold_accuracy)\n",
    "    \n",
    "    \n",
    "    print(f'Fold {len(c_index_metrics)}:')\n",
    "    print(f'  C-index: {fold_c_index:.4f}')\n",
    "    print(f'  Accuracy: {fold_accuracy:.4f}')\n",
    "    print('-'*40)\n",
    "\n",
    "\n",
    "print('\\n汇总结果:')\n",
    "print(f'平均 C-index: {np.mean(c_index_metrics):.4f} (±{np.std(c_index_metrics):.4f})')\n",
    "print(f'调整后 C-index: {np.mean(c_index_metrics) - np.sqrt(np.var(c_index_metrics)):.4f}')\n",
    "print(f'\\n平均准确率: {np.mean(accuracies):.4f} (±{np.std(accuracies):.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8089d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集前几个预测的概率: [0.17383564 0.64654589 0.09964097]\n"
     ]
    }
   ],
   "source": [
    "test_data = test_data[X.columns]\n",
    "\n",
    "test_predictions = model.predict_proba(test_data)[:, 1]  # 获取属于类别1的概率\n",
    "\n",
    "# 输出预测的前几个结果\n",
    "print(\"测试集前几个预测的概率:\", test_predictions[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34573d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交结果已保存为 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'ID': id_column, 'prediction': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"提交结果已保存为 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759edf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
